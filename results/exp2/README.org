#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}

* Setup
This experiment tests the performance improvement of running function
prediction on the DREAM networks after denoising the networks in
various ways.

We look at class of denoising methods that all work by adding new
edges to the network based off of some link predictor. In our case,
the methods add the top 10% of edges from the link predictor to the
network with a constant weight of 1.

There are 3 link prediction algorithms used:
- Pairwise distance predictor under normalized DSD
- GLIDE predictor under the L3 metric
- GLIDE predictor under the commone weighted metric

The parameters for the GLIDE predictor used in the experiment
are as follows: 

#+BEGIN_EXPORT latex
\begin{minted}[mathescape, 
               xleftmargin=2pt, 
               xrightmargin=2pt, 
               style=autumn, 
               framesep=3mm,
               frame=lines
               ]{python}
params = {"alpha" : 1, "beta" : 1000, "delta" : 0.001, "loc" : "l3"}
params = {"alpha" : 1, "beta" : 1000, "delta" : 0.001, "loc" : "cw"}
\end{minted}
#+END_EXPORT

Performance was evaluated using 5-fold CV with the GO label set from
2019 where all GO labels annotating less than 50 or greater than 1000
proteins are discared (I use Lily's code to do this).

* Results
The accuracy for each method is listed below:

|         | Normalized DSD | GLIDE CW | Glide L3 | Network Enhancement | No Denoising |
|---------+----------------+----------+----------+---------------------+--------------|
| Dream 1 |          0.197 |    0.161 |    0.163 |               0.239 |        0.246 |
| Dream 2 |          0.133 |    0.132 |    0.123 |               0.145 |        0.132 |
| Dream 3 |          0.143 |    0.152 |    0.139 |               0.180 |        0.125 |
| Dream 4 |          0.114 |    0.114 |    0.116 |               0.120 |        0.138 |
| Dream 5 |          0.082 |    0.074 |    0.075 |               0.078 |        0.071 |
| Dream 6 |          0.190 |    0.192 |    0.192 |               0.202 |        0.166 |
| Average |          0.143 |    0.137 |    0.135 |               0.161 |        0.146 |

* Conclusion
